"use strict";(self.webpackChunkp2panda_website=self.webpackChunkp2panda_website||[]).push([[5782],{3905:function(e,n,t){t.d(n,{Zo:function(){return d},kt:function(){return h}});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var p=a.createContext({}),s=function(e){var n=a.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},d=function(e){var n=s(e.components);return a.createElement(p.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=s(t),h=r,m=u["".concat(p,".").concat(h)]||u[h]||c[h]||o;return t?a.createElement(m,i(i({ref:n},d),{},{components:t})):a.createElement(m,i({ref:n},d))}));function h(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=u;var l={};for(var p in n)hasOwnProperty.call(n,p)&&(l[p]=n[p]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var s=2;s<o;s++)i[s]=t[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},2586:function(e,n,t){t.r(n),t.d(n,{assets:function(){return p},contentTitle:function(){return i},default:function(){return c},frontMatter:function(){return o},metadata:function(){return l},toc:function(){return s}});var a=t(3117),r=(t(7294),t(3905));const o={id:"replication"},i="Replication",l={unversionedId:"networking/replication",id:"networking/replication",title:"Replication",description:"- replication is the process by which nodes exchange entries and operations to eventually converge all to the same state",source:"@site/docs/03-networking/replication.md",sourceDirName:"03-networking",slug:"/networking/replication",permalink:"/handbook/docs/networking/replication",draft:!1,editUrl:"https://github.com/p2panda/handbook/edit/main/website/docs/03-networking/replication.md",tags:[],version:"current",frontMatter:{id:"replication"},sidebar:"docs",previous:{title:"Discovery",permalink:"/handbook/docs/networking/discovery"},next:{title:"Collaboration",permalink:"/handbook/docs/category/collaboration"}},p={},s=[{value:"Node API",id:"node-api",level:2},{value:"<code>entryByHash</code>",id:"entrybyhash",level:3},{value:"<code>entryByLogIdAndSeqNum</code>",id:"entrybylogidandseqnum",level:3},{value:"<code>entriesNewerThanSeqNum</code>",id:"entriesnewerthanseqnum",level:3},{value:"Encoded entries with operation",id:"encoded-entries-with-operation",level:3},{value:"Pagination",id:"pagination",level:3},{value:"Transport protocol",id:"transport-protocol",level:2},{value:"GraphQL over HTTP",id:"graphql-over-http",level:3},{value:"GraphQL over qp2p",id:"graphql-over-qp2p",level:3},{value:"Encryption",id:"encryption",level:3},{value:"Replication protocol",id:"replication-protocol",level:2},{value:"Basic Replication",id:"basic-replication",level:3}],d={toc:s};function c(e){let{components:n,...t}=e;return(0,r.kt)("wrapper",(0,a.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"replication"},"Replication"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"replication is the process by which nodes exchange entries and operations to eventually converge all to the same state",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"this makes p2panda an ",(0,r.kt)("em",{parentName:"li"},"eventually consistent")," database"),(0,r.kt)("li",{parentName:"ul"},"nodes autonomously share data with each other without central coordination"))),(0,r.kt)("li",{parentName:"ul"},"nodes may not be interested in all available data and can choose to receive only some data",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"for example from a set of authors or schemas")))),(0,r.kt)("h2",{id:"node-api"},"Node API"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"this api consists of GraphQL queries for other nodes to ask about the state of bamboo logs, entries and payloads",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"these queries are enough to build a flexible replication protocol on top"))),(0,r.kt)("li",{parentName:"ul"},"nodes need to implement the API specifications to make sure they are compatible with all other node and client implementations. The Node API is specified here, the Client API is further specified under ",(0,r.kt)("a",{parentName:"li",href:"/docs/organising-data/queries"},"queries"),", both APIs reside inside nodes")),(0,r.kt)("h3",{id:"entrybyhash"},(0,r.kt)("inlineCode",{parentName:"h3"},"entryByHash")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},'"""\nget an entry by its hash\n"""\nentryByHash(hash: EntryHash!): EncodedEntryAndOperation\n')),(0,r.kt)("h3",{id:"entrybylogidandseqnum"},(0,r.kt)("inlineCode",{parentName:"h3"},"entryByLogIdAndSeqNum")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},'"""\nget a single entry by its log id, sequence number and public key\n"""\nentryByLogIdAndSeqNum(\n  """\n  id of the log\n  """\n  logId: LogId!\n\n  """\n  public key of author of the log\n  """\n  public_key: PublicKey!\n\n  """\n  sequence number of the entry in the log\n  """\n  seqNum: SeqNum!\n): EncodedEntryAndOperation\n')),(0,r.kt)("h3",{id:"entriesnewerthanseqnum"},(0,r.kt)("inlineCode",{parentName:"h3"},"entriesNewerThanSeqNum")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"used as the main query for replication, see process defined further below")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},'"""\nget any entries that are newer than the provided sequence_number for a given\npublic key and log_id\n"""\nentriesNewerThanSeqNum(\n  """\n  id of the log\n  """\n  logId: LogId!\n\n  """\n  public key of author of the log\n  """\n  public_key: PublicKey!\n\n  """\n  latest known sequence number. we want the entries which are newer than this,\n  defaults to 0\n  """\n  seqNum: SeqNum\n\n  """\n  max number of items to be returned per page, defaults to 10\n  """\n  first: Int\n\n  """\n  cursor identifier for pagination\n  """\n  after: String\n): EncodedEntryAndOperationConnection!\n')),(0,r.kt)("h3",{id:"encoded-entries-with-operation"},"Encoded entries with operation"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},'type EncodedEntryAndOperation {\n  """\n  entry bytes encoded as hexadecimal string\n  """\n  entry: EncodedEntry!\n\n  """\n  operation (payload of the entry) bytes encoded as hexadecimal string\n  """\n  operation: EncodedOperation\n\n  """\n  get the certificate pool for this entry that can be used to verify the entry\n  is valid\n  """\n  certificatePool: [EncodedEntry!]!\n}\n')),(0,r.kt)("h3",{id:"pagination"},"Pagination"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-graphql"},'type EncodedEntryAndOperationConnection {\n  """\n  information to aid in pagination\n  """\n  pageInfo: PageInfo!\n\n  """\n  a list of edges.\n  """\n  edges: [EncodedEntryAndOperationEdge]\n}\n\n"""\nan edge in a connection\n"""\ntype EncodedEntryAndOperationEdge {\n  """\n  the item at the end of the edge\n  """\n  node: EncodedEntryAndOperation!\n\n  """\n  a cursor for use in pagination\n  """\n  cursor: String!\n}\n\n"""\ninformation about pagination in a connection\n"""\ntype PageInfo {\n  """\n  when paginating backwards, are there more items?\n  """\n  hasPreviousPage: Boolean!\n\n  """\n  when paginating forwards, are there more items?\n  """\n  hasNextPage: Boolean!\n\n  """\n  when paginating backwards, the cursor to continue\n  """\n  startCursor: String\n\n  """\n  when paginating forwards, the cursor to continue\n  """\n  endCursor: String\n}\n')),(0,r.kt)("h2",{id:"transport-protocol"},"Transport protocol"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"p2panda replication protocol is based on the GraphQL query language",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"this allows developers to easily build their p2panda replication implementations in any programming language"),(0,r.kt)("li",{parentName:"ul"},'this allows "leecher" node implementations in the browser which collect and persist entries but do not communicate and replicate further with other nodes')))),(0,r.kt)("h3",{id:"graphql-over-http"},"GraphQL over HTTP"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"the GraphQL queries can be made via HTTP against ",(0,r.kt)("inlineCode",{parentName:"li"},"<host>:2020/graphql"))),(0,r.kt)("h3",{id:"graphql-over-qp2p"},"GraphQL over qp2p"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"nodes can offer a ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/maidsafe/qp2p"},"qp2p")," endpoint on port ",(0,r.kt)("inlineCode",{parentName:"li"},"2022")," for replication via the qp2p (QUIC, TLS 1.3) protocol"),(0,r.kt)("li",{parentName:"ul"},"qp2p is a p2p messaging protocol sending discrete GraphQL queries over QUIC streams, it ..",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"has built-in support for the Internet Gateway Device Protocol (IGD) for automatic port forwarding for peers behind NAT-enabled routers"),(0,r.kt)("li",{parentName:"ul"},"is based on the QUIC streaming protocol supporting both unidirectional and bidirectional streams"),(0,r.kt)("li",{parentName:"ul"},"has a fault-tolerancy mechanism"),(0,r.kt)("li",{parentName:"ul"},"makes use of connection pooling, for reusing already opened connections")))),(0,r.kt)("h3",{id:"encryption"},"Encryption"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"data over qp2p and regular HTTP transport connection is secured via TLS 1.3"),(0,r.kt)("li",{parentName:"ul"},"TLS certificates are self-signed certificates by default",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"this allows transport encryption without a centralised certificate authority (CA)"),(0,r.kt)("li",{parentName:"ul"},"this doesn't give authentication but since p2panda data is already authenticated and designed to function in a trustless network setting, this doesn't need to be reflected on this layer"),(0,r.kt)("li",{parentName:"ul"},"optionally a p2panda node can be moved behind a reverse-proxy providing its own certificates")))),(0,r.kt)("h2",{id:"replication-protocol"},"Replication protocol"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"the replication protocol defines the process of exchanging entries and p2panda operations on top of the GraphQL Node API")),(0,r.kt)("h3",{id:"basic-replication"},"Basic Replication"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"retreives new entries from another node"),(0,r.kt)("li",{parentName:"ul"},"more sophisticated replication protocols can be built on top",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},'the "basic replication" protocol serves as a base'),(0,r.kt)("li",{parentName:"ul"},"nodes may not be interested in all available data and can choose to receive only some data, for example by only requesting operations following a certain schema")))),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Process")),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Node ",(0,r.kt)("inlineCode",{parentName:"li"},"A")," gets latest known sequence number ",(0,r.kt)("inlineCode",{parentName:"li"},"s")," for log ",(0,r.kt)("inlineCode",{parentName:"li"},"k")," of author ",(0,r.kt)("inlineCode",{parentName:"li"},"p")," from own database"),(0,r.kt)("li",{parentName:"ol"},"Node ",(0,r.kt)("inlineCode",{parentName:"li"},"A")," makes a GraphQL request ",(0,r.kt)("inlineCode",{parentName:"li"},"entriesNewerThanSeqNum")," and asks Node ",(0,r.kt)("inlineCode",{parentName:"li"},"B")," if it has newer entries of log ",(0,r.kt)("inlineCode",{parentName:"li"},"k")," and author ",(0,r.kt)("inlineCode",{parentName:"li"},"p")," starting from sequence number ",(0,r.kt)("inlineCode",{parentName:"li"},"s")),(0,r.kt)("li",{parentName:"ol"},"Node ",(0,r.kt)("inlineCode",{parentName:"li"},"B")," replies with a paginated list of encoded entries and operations. If it doesn't have that log or if there are no newer entries, it replies with an empty result"),(0,r.kt)("li",{parentName:"ol"},"Node ",(0,r.kt)("inlineCode",{parentName:"li"},"A")," paginates through the response until it downloaded all new entries, it validates them locally and stores them in its database. Node ",(0,r.kt)("inlineCode",{parentName:"li"},"A")," can make use of the ",(0,r.kt)("inlineCode",{parentName:"li"},"certificatePool")," field of ",(0,r.kt)("inlineCode",{parentName:"li"},"EncodedEntryAndOperation")," if it doesn't have the full log locally to verify it")))}c.isMDXComponent=!0}}]);